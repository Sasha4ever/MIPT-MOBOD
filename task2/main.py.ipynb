{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    export ARTM_SHARED_LIBRARY=/Users/salik/Projects/mobod/bigartm/build/src/artm/libartm.dylib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import artm\n",
    "os.environ['ARTM_SHARED_LIBRARY']='/Users/salik/Projects/MIPT-MOBOD/bigartm/build/src/artm/libartm.dylib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Скачать данные hillary-clinton-emails с сайта kaggle.com (потребуется регистра- ция).\n",
    "## Взять из данных полные тексты писем и создать из них файл в формате Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_directory = 'hillary-clinton-emails'\n",
    "emails = pd.read_csv(os.path.join(data_directory, 'Emails.csv'))\n",
    "vec = CountVectorizer(decode_error='replace')\n",
    "X = vec.fit_transform(emails.RawText).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df['subject'] = emails['ExtractedSubject']\n",
    "df['id'] = emails['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1 = df.copy()\n",
    "Y = X1['id']\n",
    "X1 = X1.drop('id', axis=1)\n",
    "X1 = X1.drop('subject', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_svmlight_file(X1, Y, './dump_svmlight_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = {val: key for key, val in zip(vec.vocabulary_.keys(), vec.vocabulary_.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./vowpal_wabbit.dat', 'w+') as vowpal_wabbit_file:\n",
    "    for line in open('./dump_svmlight_file.csv'):\n",
    "        try:\n",
    "            y, x = line.split( \" \", 1 )\n",
    "        except ValueError:\n",
    "            pass\n",
    "        features_artm = []\n",
    "        for s in x.split(' '):\n",
    "            try:\n",
    "                features_artm.append(':'.join([tokens[int(s.split(':')[0])], s.split(':')[1]]))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "        new_line = 'doc' + y + ' ' + ' '.join(features_artm).encode('utf-8')\n",
    "        vowpal_wabbit_file.write( new_line )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создать батчи и словарь коллекции в соответствии с инструкциями из учебного ноутбука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch = artm.BatchVectorizer(data_path='vowpal_wabbit.dat',\n",
    "                                        data_format='vowpal_wabbit',\n",
    "                                        target_folder='batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dictionary = artm.Dictionary()\n",
    "my_dictionary.gather(data_path='batches')\n",
    "my_dictionary.filter(min_tf=10, max_tf=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Написать скрипт для обучения обучения модели с регуляризаторами. Рекомен- дуется обучать модель с 25-30 темами. Рекомендуется использовать регуляри- затор разреживания и декорреляции тем.\n",
    "## После обучения каждой модели извлекать из неё топ-20 самых вероятных слов вместе с их вероятностями и оценивать степень интерпретируемости тем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379.27444163511956"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = artm.ARTM(num_topics=25, dictionary=my_dictionary)\n",
    "model.scores.add(artm.PerplexityScore(name='my_fisrt_perplexity_score',\n",
    "                                      use_unigram_document_model=False,\n",
    "                                      dictionary=my_dictionary))\n",
    "model.fit_offline(batch_vectorizer=batch, num_collection_passes=10)\n",
    "model.score_tracker['my_fisrt_perplexity_score'].last_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = artm.ARTM(num_topics=25, dictionary=my_dictionary, cache_theta=False)\n",
    "model.scores.add(artm.PerplexityScore(name='PerplexityScore',\n",
    "                                      use_unigram_document_model=False,\n",
    "                                      dictionary=my_dictionary))\n",
    "model.scores.add(artm.SparsityThetaScore(name='SparseTheta'))\n",
    "model.scores.add(artm.TopTokensScore(name='TopTokensScore'))\n",
    "model.fit_offline(batch_vectorizer=batch, num_collection_passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379.274454588\n",
      "0.00492950654582\n",
      "topic_0:  [u'party', u'were', u'cameron', u'which', u'government', u'labour', u'election', u'out', u'tories', u'uk']\n",
      "topic_1:  [u'china', u'pakistan', u'countries', u'world', u'people', u'rights', u'human', u'government', u'development', u'global']\n",
      "topic_2:  [u'jacob', u'me', u'sullivanjj', u'sun', u'11', u'12', u'sunday', u'know', u'should', u'b5']\n",
      "topic_3:  [u'obama', u'mr', u'clinton', u'when', u'administration', u'him', u'says', u'white', u'some', u'policy']\n",
      "topic_4:  [u'my', u'afghanistan', u'me', u'were', u'afghan', u'think', u'when', u'know', u'clinton', u'your']\n",
      "topic_5:  [u'office', u'00', u'meeting', u'15', u'room', u'en', u'12', u'45', u'11', u'arrive']\n",
      "topic_6:  [u'israel', u'israeli', u'peace', u'palestinian', u'netanyahu', u'palestinians', u'jewish', u'arab', u'jerusalem', u'talks']\n",
      "topic_7:  [u'hdr22', u'abedinh', u'sat', u'lona', u'18', u'21', u'fri', u'hrod17', u'valmoro', u'aug']\n",
      "topic_8:  [u'security', u'united', u'states', u'international', u'national', u'government', u'these', u'other', u'agency', u'force']\n",
      "topic_9:  [u'sensitive', u'benghazi', u'libya', u'al', u'libyan', u'source', u'information', u'produced', u'13', u'house']\n",
      "topic_10:  [u'anne', u'your', u'marie', u'slaughter', u'http', u'sid', u'judith', u'mchale', u'sbwhoeop', u'www']\n",
      "topic_11:  [u'united', u'its', u'government', u'states', u'american', u'military', u'iran', u'support', u'security', u'statement']\n",
      "topic_12:  [u'news', u'fw', u'speech', u'ses', u'ap', u'abedinh', u'december', u'reuters', u'mahogany', u'lissa']\n",
      "topic_13:  [u'13', u'house', u'september', u'05', u'benghazi', u'information', u'update', u'2012', u'dept', u'sensitive']\n",
      "topic_14:  [u'public', u'af', u'diplomacy', u'affairs', u'africa', u'million', u'people', u'pdpa', u'koch', u'policy']\n",
      "topic_15:  [u'haiti', u'january', u'jan', u'fw', u'un', u'millscd', u'honduras', u'haitian', u'craig', u'au']\n",
      "topic_16:  [u'her', u'she', u'clinton', u'branch', u'wjc', u'gore', u'berlin', u'hillary', u'palau', u'women']\n",
      "topic_17:  [u'agreement', u'benghazi', u'05', u'information', u'comm', u'sensitive', u'04841', u'redactions', u'produced', u'dept']\n",
      "topic_18:  [u'percent', u'obama', u'than', u'policy', u'its', u'world', u'germany', u'nuclear', u'states', u'american']\n",
      "topic_19:  [u'fw', u'millscd', u'fyi', u'jacob', u'b5', u'202', u'april', u'wednesday', u'david', u'647']\n",
      "topic_20:  [u'senate', u'house', u'republican', u'http', u'party', u'bill', u'republicans', u'democrats', u'health', u'obama']\n",
      "topic_21:  [u'lauren', u'jiloty', u'jilotylc', u'talk', u'tuesday', u'hrod17', u'29', u'b1', u'abedinh', u'ok']\n",
      "topic_22:  [u'women', u'children', u'haiti', u'development', u'education', u'health', u'work', u'food', u'people', u'school']\n",
      "topic_23:  [u'iran', u'foreign', u'minister', u'government', u'iranian', u'reuters', u'http', u'news', u'sudan', u'election']\n",
      "topic_24:  [u'email', u'aid', u'any', u'africa', u'clinton', u'your', u'team', u'visit', u'please', u'min']\n"
     ]
    }
   ],
   "source": [
    "print model.score_tracker['PerplexityScore'].last_value\n",
    "print model.score_tracker['SparseTheta'].last_value\n",
    "for topic_name in model.topic_names:\n",
    "    print topic_name + ': ',\n",
    "    print model.score_tracker['TopTokensScore'].last_tokens[topic_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = artm.ARTM(num_topics=25, dictionary=my_dictionary)\n",
    "model.scores.add(artm.PerplexityScore(name='PerplexityScore',\n",
    "                                      use_unigram_document_model=False,\n",
    "                                      dictionary=my_dictionary))\n",
    "model.scores.add(artm.TopTokensScore(name='TopTokensScore', num_tokens=20))\n",
    "\n",
    "model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='SparsePhi', tau=-2.0))\n",
    "model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='SparseTheta', tau=-1))\n",
    "model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='DecorrelatorPhi', tau=1e+7))\n",
    "model.fit_offline(batch_vectorizer=batch, num_collection_passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537.710873541\n",
      "topic_0:  [u'dems', u'zardari', u'psd', u'klobuchar', u'c05771734', u'debates', u'turk', u'much', u'boucher', u'saeb', u'manley', u'stolen', u'fogh', u'precious', u'95', u'dept', u'estate', u'havens', u'dad', u'laurie']\n",
      "topic_1:  [u'quarter', u'shaw', u'jabar', u'pittman', u'winthrop', u'pillsbury', u'kosovo', u'abdul', u'verde', u'thailand', u'portugal', u'leaks', u'proof', u'sugar', u'hot', u'electricity', u'zimbabwe', u'verdict', u'gloria', u'forth']\n",
      "topic_2:  [u'turkey', u'text', u'davutoglu', u'armenia', u'agree', u'c05763192', u'davu', u'bajnai', u'slovenia', u'truly', u'convoy', u'somebody', u'brits', u'duffy', u'easter', u'dirksen', u'mom', u'bp', u'laugh', u'apologies']\n",
      "topic_3:  [u'among', u'important', u'care', u'far', u'post', u'americans', u'better', u'future', u'whether', u'leader', u'others', u'community', u'chief', u'campaign', u'law', u'early', u'days', u'doing', u'home', u'put']\n",
      "topic_4:  [u'thomas', u'taliban', u'petraeus', u'pakistani', u'karzai', u'attorney', u'anthony', u'generals', u'hussain', u'yohannes', u'friendly', u'afghans', u'pakistanis', u'schumer', u'heavily', u'2c', u'lobby', u'simpson', u'empire', u'recalled']\n",
      "topic_5:  [u'depart', u'route', u'c05763169', u'c05763586', u'c05766032', u'c05765906', u'teleconference', u'c05771805', u'7516', u'outlook', u'jefferson', u'preparation', u'c05762496', u'turk', u'much', u'boucher', u'saeb', u'manley', u'stolen', u'fogh']\n",
      "topic_6:  [u'neighborhood', u'napolitano', u'c05766168', u'nujood', u'warming', u'microsoft', u'explosion', u'vmi', u'eta', u'thread', u'assumed', u'flights', u'kramer', u'187', u'700', u'amnesty', u'ocs', u'user', u'postmaster', u'23d3']\n",
      "topic_7:  [u'philippe', u'de', u'valmorou', u'reines', u'dinner', u'pls', u'branch', u'52', u'wjc', u'pir', u'preines', u'carter', u'reinesp', u'que', u'jimmy', u'russo', u'stock', u'shouldn', u'polish', u'russorv']\n",
      "topic_8:  [u'diagnostic', u'turk', u'much', u'boucher', u'saeb', u'manley', u'stolen', u'fogh', u'precious', u'95', u'dept', u'estate', u'havens', u'dad', u'laurie', u'15th', u'spies', u'force', u'james', u'downside']\n",
      "topic_9:  [u'sis', u'mali', u'salafist', u'deyo', u'c05762731', u'imminent', u'immigrant', u'refaming', u'laszczychj', u'mentor', u'5548', u'c05766722', u'butzgy', u'8633', u'6pm', u'turk', u'much', u'boucher', u'saeb', u'manley']\n",
      "topic_10:  [u'mchale', u'minutes', u'amazon', u'baucus', u'pelletier', u'tauzin', u'pharmaceutical', u'c05763138', u'murtha', u'mumbai', u'ecx', u'cpao', u'c05761078', u'c05766696', u'kenna', u'corley', u'hormats', u'krishna', u'aung', u'npr']\n",
      "topic_11:  [u'zelaya', u'nfa', u'visas', u'facto', u'prosecutor', u'abd', u'censorship', u'c05772410', u'yussef', u'correa', u'strikes', u'csis', u'motivated', u'broadcast', u'rok', u'charlie', u'baby', u'ruled', u'rieser', u'divide']\n",
      "topic_12:  [u'slaughter', u'lissa', u'muscatine', u'internet', u'qddr', u'bbc', u'track', u'jon', u'productivity', u'scenario', u'version', u'ct', u'deals', u'mcconnell', u'contribution', u'complaints', u'executives', u'grown', u'fisa', u'frustration']\n",
      "topic_13:  [u'pouch', u'funny', u'sufi', u'stating', u'piercy', u'nyu', u'bass', u'announces', u'tys', u'rosemarie', u'concert', u'kenyan', u'indyk', u'rooneym', u'spanta', u'sf', u'cartwright', u'comi', u'coat', u'carmen']\n",
      "topic_14:  [u'qaddafi', u'keib', u'believes', u'pdpa', u'establish', u'c05770301', u'abdel', u'c05770985', u'yezza', u'2013', u'functions', u'lnc', u'supporters', u'c05739610', u'c05739812', u'organizational', u'indicators', u'loyal', u'publics', u'credentials']\n",
      "topic_15:  [u'micheletti', u'aceh', u'lanny', u'erica', u'fr', u'secc', u'wynn', u'cowen', u'mprr', u'020510', u'c05769531', u'wen', u'c05764171', u'yang', u'wfp', u'folder', u'kurtzer', u'moratinos', u'att', u'penn']\n",
      "topic_16:  [u'samoa', u'haji', u'c05767922', u'turk', u'much', u'boucher', u'saeb', u'manley', u'stolen', u'fogh', u'precious', u'95', u'dept', u'estate', u'havens', u'dad', u'laurie', u'15th', u'spies', u'force']\n",
      "topic_17:  [u'guardian', u'dup', u'northern', u'robinson', u'devolved', u'unionists', u'stormont', u'devolution', u'allister', u'dissidents', u'tobacco', u'favour', u'regan', u'inspirational', u'castle', u'gaining', u'tuv', u'granger', u'hyman', u'stalemate']\n",
      "topic_18:  [u'holocaust', u'c05771526', u'jersey', u'eve', u'worn', u'hvn', u'attitudes', u'technologies', u'iroquois', u'qadahfi', u'71', u'blow', u'63', u'c05771170', u'c05762698', u'turk', u'much', u'boucher', u'saeb', u'manley']\n",
      "topic_19:  [u'ses', u'dc', u'44', u'ap', u'jim', u'cdm', u'reuters', u'michael', u'verma', u'daniel', u'58', u'57', u'41', u'deputy', u'39', u'36', u'james', u'56', u'phone', u'philip']\n",
      "topic_20:  [u'boehner', u'evite', u'contrast', u'jsp', u'independents', u'edu', u'click', u'provinces', u'mordica', u'luce', u'currency', u'sosiltd', u'factors', u'barriers', u'fma', u'privacy', u'weiner', u'store', u'c05766135', u'effects']\n",
      "topic_21:  [u'c05762308', u'crown', u'kyrgyz', u'moriarty', u'bakiyev', u'appeals', u'interrogation', u'armitage', u'nutrition', u'dep', u'moroccan', u'prm', u'fmr', u'spill', u'starts', u'unfolds', u'astoria', u'rothman', u'isabelle', u'stanford']\n",
      "topic_22:  [u'heyman', u'lemieux', u'saba', u'newmyer', u'villarreal', u'cloakroom', u'c05766070', u'ghori', u'schrayer', u'riots', u'usglc', u'c05767011', u'gaf', u'c05771806', u'brainard', u'tt', u'voinovich', u'txt', u'feehery', u'v7']\n",
      "topic_23:  [u'saudi', u'king', u'arabia', u'doha', u'corp', u'spend', u'hikers', u'blogging', u'ig', u'chuckle', u'highlighted', u'colin', u'petroleos', u'iranians', u'ankara', u'assess', u'supplemental', u'height', u'pamela', u'scrap']\n",
      "topic_24:  [u'windrush', u'fistula', u'sw1h', u'aclb', u'lp', u'obl', u'freeman', u'du', u'finca', u'wales', u'reserved', u'estados', u'unidos', u'capweb', u'facilitator', u'smits', u'messagelabs', u'ak', u'provisions', u'accurate']\n"
     ]
    }
   ],
   "source": [
    "print model.score_tracker['PerplexityScore'].last_value\n",
    "for topic_name in model.topic_names:\n",
    "    print topic_name + ': ',\n",
    "    print model.score_tracker['TopTokensScore'].last_tokens[topic_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "cont, counter = {}, 1\n",
    "for topic_index, topic_name in enumerate(tqdm.tqdm_notebook(model.topic_names, desc=\"topics\")):\n",
    "    score_tracker = model.score_tracker['TopTokensScore']\n",
    "    for i in tqdm.tqdm_notebook(xrange(len(score_tracker.last_tokens[topic_name])), desc=\"tokens\"):\n",
    "        cont[score_tracker.last_tokens[topic_name][i]] = counter\n",
    "        counter += 1\n",
    "model_topic_names = model.topic_names\n",
    "model_score_tracker = model.score_tracker\n",
    "score_tracker_last_tokens = score_tracker.last_tokens\n",
    "score_tracker_last_weights = score_tracker.last_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('gephi.gexf', 'wb') as f:\n",
    "    num_top_tokens = 20 \n",
    "    num_topics = 25 \n",
    "    f.write('<gexf xmlns:viz=\"http:///www.gexf.net/1.1draft/viz\" xmlns=\"http://www.gexf.net/1.1draft\" version=\"1.1\">\\n')\n",
    "    f.write('<meta lastmodifieddate=\"2010-03-03+23:44\">\\n')\n",
    "    f.write('<creator>Gephi 0.7</creator>\\n')\n",
    "    f.write('</meta>\\n')\n",
    "    f.write('<graph defaultedgetype=\"undirected\" idtype=\"string\" type=\"static\">\\n')\n",
    "    f.write('<nodes count=\"{}\">\\n'.format(len(cont) + num_topics))\n",
    "    \n",
    "    for token, value in cont.iteritems():\n",
    "        f.write('<node id=\"{0}\" label=\"{1}\"/>\\n'.format(value, token))\n",
    "        for id in xrange(num_topics):\n",
    "            f.write('<node id=\"{0}\" label=\"TOPIC_{1}\"/>\\n'.format(num_top_tokens * num_topics + id, id))\n",
    "            \n",
    "    f.write('</nodes>\\n')\n",
    "            \n",
    "    edge_id = 0\n",
    "    strs_to_write = []\n",
    "    score_tracker_last_tokens = score_tracker.last_tokens\n",
    "    score_tracker_last_weights = score_tracker.last_weights\n",
    "    for token, value in cont.iteritems():\n",
    "        for topic_index, topic_name in enumerate(model_topic_names):\n",
    "            score_tracker = model_score_tracker['TopTokensScore']\n",
    "            for i in xrange(len(score_tracker_last_tokens[topic_name])):\n",
    "                if score_tracker_last_tokens[topic_name][i] == token:\n",
    "                    strs_to_write.append('<edge id=\"{0}\" source=\"{1}\" target=\"{2}\" weight=\"{3}\"/>\\n'.format(\n",
    "                    edge_id, num_top_tokens * num_topics + topic_index, value, score_tracker_last_weights[topic_name][i]))\n",
    "                    edge_id += 1\n",
    "    f.write('<edges count=\"{}\">\\n'.format(len(strs_to_write)))\n",
    "    for elem in strs_to_write:\n",
    "        f.write(elem)\n",
    "        \n",
    "    f.write('</edges>\\n')\n",
    "    f.write('</graph>\\n')\n",
    "    f.write('</gexf>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "1d84e237cf034ec288798c8fb92fe614": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "203d0e8f1bef4051a8f2aa8d256525f8": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "2fb904f52e424394a435654dcb56084f": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "75ec3d1f7f7b49fda5593b36348d47a4": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "8e0b95b71cd9416985db5c60b7f9b6de": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "a1367837c4914cd5820dce986963a4b0": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "a74db4b3c6554f2aaba8a57eac8c838d": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "ac977163efc04f76bc6942bea7eef738": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "afd837d1c3284a8ea29d085f7622fef5": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "b7c4df48daa541aca038f9cfe3b84718": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "f97abde254304cd4923a0552a8270879": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
